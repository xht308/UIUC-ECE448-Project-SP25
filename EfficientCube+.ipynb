{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a46d128b",
   "metadata": {},
   "source": [
    "# EfficientCube+: DNN-based Rubik's Cube Solver\n",
    "\n",
    "## Overview\n",
    "The standalone notebook serves as a demostration of the methods proposed in our ECE448 Final Project @ UIUC in SP2025 and provides the necessary code to reproduce the experiment.\n",
    "\n",
    "## Related work\n",
    "The work is based on the the following publiciation:\n",
    "> K. Takano. Self-Supervision is All You Need for Solving Rubik's Cube. Transactions on Machine Learning Research, ISSN 2835-8856, 2023. URL: https://openreview.net/forum?id=bnBeNFB27b.\n",
    "\n",
    "## Environment Reference\n",
    "The notebook is designed to be run and tested on [Illinois Computes Research Notebooks](http://go.ncsa.illinois.edu/jupyter) (ICRN), which is equipped with the following resources:\n",
    "- AMD EPYC-Milan Processor Core * 2\n",
    "- 8GB of RAM\n",
    "- NVIDIA A100-SXM4-80GB (shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbdc4b0",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Due to the short time period of the project and the limited resources, the default training and searching configuration is sub-optimal aimed to achieve a balance between time/resource consumption and the performance of the resulting model.\n",
    "\n",
    "To make comparsion to and reproduce the best-reported result and in the original [EfficientCube](https://github.com/kyo-takano/efficientcube) project, which we refered to, it is suggested to set `TrainConfig.num_steps = 2000000` and `SearchConfig.beam_width = 2**18`.\n",
    "\n",
    "To accelerate training and inference, the mixed precision mode can be enabled by setting `ENABLE_FP16` to `True` with possible minor performance degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3476c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainConfig:\n",
    "    max_depth = 26                          # God's Number\n",
    "    batch_size_per_depth = 1000\n",
    "    num_steps = 10000\n",
    "    learning_rate = 1e-3\n",
    "    target_depth = [2, 6, 10, 14, 26]              # The depths to be shown in the training plot\n",
    "    depth_colors = [\"g\", \"c\", \"m\", \"b\", \"r\"]          # The colors to be used for the depths in the training plot\n",
    "    INTERVAL_PLOT, INTERVAL_SAVE = 100, 1000\n",
    "    ENABLE_FP16 = False                     # Set this to True if you want to train the model faster\n",
    "    SAVED_MODEL = None                      # Set this to the path of a saved model if you want to skip training\n",
    "    SHOW_DEPTH_LOSS = True                  # Set this to True if you want to see the depth loss\n",
    "\n",
    "class SearchConfig:\n",
    "    beam_width = 2**11                      # This controls the trade-off between time and optimality\n",
    "    max_depth = TrainConfig.max_depth * 2   # Any number above God's Number will do\n",
    "    ENABLE_FP16 = False                     # Set this to True if you want to solve faster\n",
    "\n",
    "class ReinforcementConfig:\n",
    "    # NOTICE: This is a work in progress and not yet fully implemented\n",
    "    # The current training settings are not carefully tuned and may significantly lower the performance of the model\n",
    "\n",
    "    # NOTE: Enabling reinforcement learning will change the model architecture\n",
    "    ##  Make sure to retrain the model or load the correct checkpoint every time you enable or disable it\n",
    "    ENABLE = False\n",
    "    batch_size = 32\n",
    "    num_steps = 10000\n",
    "    learning_rate = 1e-4\n",
    "    depths = list(range(2, 6))\n",
    "    max_depth = TrainConfig.max_depth * 10\n",
    "    epsilon = 0.1\n",
    "    ENABLE_FP16 = False                     # Set this to True if you want to train the model faster\n",
    "\n",
    "class ExperimentalConfig:\n",
    "    USE_TRITON = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf6cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from contextlib import nullcontext\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from cycler import cycler\n",
    "from IPython.display import clear_output\n",
    "from torch import nn\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# Set the default color cycle for matplotlib plots\n",
    "plt.rcParams[\"axes.prop_cycle\"] = cycler(color=[\"#000000\", \"#2180FE\", \"#EB4275\"])\n",
    "\n",
    "# Enable TensorFloat32 (TF32) Training/Inference on Ampere (or higher) GPUs\n",
    "# Supported on Nvidia A100 (test environment)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# Use GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ededb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic information\n",
    "print(f'device: {device}')\n",
    "print(f'os.cpu_count(): {os.cpu_count()}')\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf7e75d",
   "metadata": {},
   "source": [
    "## Rubik's Cube\n",
    "The Rubik's Cube is represented and operated based on the locations and color labels of $6\\times3\\times3$ stickers.\n",
    "\n",
    "In this work, the [Quarter-Turn Metric](https://www.speedsolving.com/wiki/index.php/Metric#QTM) (90° turns count as one move; 180°, two) is employed for the movement of the cube.\n",
    "\n",
    "Compared to the original implementation, our implementation makes full use of the **Vector and SIMD operation**, making the cube suitable to be operated on GPUs and achieved significant performance improvement on both training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd72528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cubes:\n",
    "    \"\"\"\n",
    "    A class for a set of 3x3x3 Rubik's cubes.\n",
    "\n",
    "    Each cube is represented as a 1D tensor of shape (6 * 3 * 3,).\n",
    "    Initial color:\n",
    "\n",
    "            0 0 0\n",
    "            0 Y 0\n",
    "            0 0 0\n",
    "\n",
    "    2 2 2   5 5 5   3 3 3  4 4 4\n",
    "    2 B 2   5 R 5   3 G 3  4 O 4\n",
    "    2 2 2   5 5 5   3 3 3  4 4 4\n",
    "\n",
    "            1 1 1\n",
    "            1 W 1\n",
    "            1 1 1\n",
    "    \n",
    "    Indices of state (each starting with 9*(n-1)):\n",
    "\n",
    "                 2   5   8\n",
    "                 1   4   7\n",
    "                [0]  3   6\n",
    "     20  23 26  47  50  53  29  32 35  38  41 44\n",
    "     19  22 25  46  49  52  28  31 34  37  40 43\n",
    "    [18] 21 24 [45] 48  51 [27] 30 33 [36] 39 42\n",
    "                11   14 17\n",
    "                10   13 16\n",
    "                [9]  12 15\n",
    "    \"\"\"\n",
    "\n",
    "    ## Class variables ##\n",
    "\n",
    "    # Initialization indicator\n",
    "    __initialized: bool = False\n",
    "\n",
    "    # Dtype of the cube representation (0-6 integers) and position representation (0-53 integers)\n",
    "    __dtype: torch.dtype = torch.long\n",
    "\n",
    "    # Move map for the cube\n",
    "    __MOVE_MAP = {\n",
    "        'U': (np.array([ 6,  7,  8,  5,  2,  1,  0,  3, 47, 50, 53, 29, 32, 35, 38, 41, 44, 20, 23, 26]),\n",
    "              np.array([ 0,  3,  6,  7,  8,  5,  2,  1, 20, 23, 26, 47, 50, 53, 29, 32, 35, 38, 41, 44])),\n",
    "        'D': (np.array([15, 12,  9, 10, 11, 14, 17, 16, 36, 39, 42, 18, 21, 24, 45, 48, 51, 27, 30, 33]),\n",
    "              np.array([ 9, 10, 11, 14, 17, 16, 15, 12, 18, 21, 24, 45, 48, 51, 27, 30, 33, 36, 39, 42])),\n",
    "        'R': (np.array([27, 28, 29, 32, 35, 34, 33, 30, 38, 37, 36, 15, 16, 17, 51, 52, 53,  6,  7,  8]),\n",
    "              np.array([29, 32, 35, 34, 33, 30, 27, 28, 15, 16, 17, 51, 52, 53,  6,  7,  8, 38, 37, 36])),\n",
    "        'L': (np.array([20, 23, 26, 25, 24, 21, 18, 19, 42, 43, 44,  2,  1,  0, 47, 46, 45, 11, 10,  9]),\n",
    "              np.array([26, 25, 24, 21, 18, 19, 20, 23,  2,  1,  0, 47, 46, 45, 11, 10,  9, 42, 43, 44])),\n",
    "        'F': (np.array([45, 46, 47, 50, 53, 52, 51, 48, 24, 25, 26,  0,  3,  6, 29, 28, 27, 17, 14, 11]),\n",
    "              np.array([47, 50, 53, 52, 51, 48, 45, 46,  0,  3,  6, 29, 28, 27, 17, 14, 11, 24, 25, 26])),\n",
    "        'B': (np.array([36, 37, 38, 41, 44, 43, 42, 39, 35, 34, 33, 15, 12,  9, 18, 19, 20,  2,  5,  8]),\n",
    "              np.array([38, 41, 44, 43, 42, 39, 36, 37,  2,  5,  8, 35, 34, 33, 15, 12,  9, 18, 19, 20])),\n",
    "    }\n",
    "    \n",
    "    # Faces and turn directions\n",
    "    __FACES: list[str] = [\"U\", \"D\", \"L\", \"R\", \"B\", \"F\"]\n",
    "\n",
    "    # Available rotation degrees\n",
    "    # Current only 90 degrees is supported\n",
    "    ## [90 degrees clockwise, 90 degrees counter-clockwise]\n",
    "    __DEGREES: list[str] = [\"\", \"'\"]\n",
    "\n",
    "    # Goal state of the cube\n",
    "    GOAL: torch.Tensor = torch.arange(0, 6 * 3 * 3, dtype=__dtype, device=device) // 9\n",
    "\n",
    "    ## Variables to be initialized ##\n",
    "\n",
    "    # Moves available for the cube\n",
    "    MOVES: list[str] = None\n",
    "\n",
    "    # Map of move names to indices\n",
    "    MOVE_TO_INDEX: dict[str, int] = None\n",
    "\n",
    "    # Source and target indices for the move map\n",
    "    MOVE_MAP_SOURCE: torch.Tensor = None\n",
    "    MOVE_MAP_TARGET: torch.Tensor = None\n",
    "\n",
    "    # The moves available for scrambling the cube\n",
    "    SCRAMBLE_MOVES_AVAILABLE: torch.Tensor = None\n",
    "\n",
    "    @classmethod\n",
    "    def init_class(cls, device=device) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the class variables.\n",
    "        Supposed to be called once when the class is first loaded.\n",
    "\n",
    "        Args:\n",
    "            device (str): Device to use for the tensor.\n",
    "        \"\"\"\n",
    "        # Check if the class has already been initialized\n",
    "        if cls.__initialized:\n",
    "            return\n",
    "        \n",
    "        # Initialize the moves available for the cube\n",
    "        cls.MOVES = [f\"{face}{degree}\" for degree in cls.__DEGREES for face in cls.__FACES]\n",
    "\n",
    "        # Initialize the move-to-index mapping\n",
    "        cls.MOVE_TO_INDEX = {move: i for i, move in enumerate(cls.MOVES)}\n",
    "\n",
    "        # Initialize the source and target indices for the move map\n",
    "        cls.MOVE_MAP_SOURCE = torch.tensor(np.array([cls.__MOVE_MAP[move[0]][0 if \"'\" not in move else 1] for move in cls.MOVES]), dtype=cls.__dtype, device=device)\n",
    "        cls.MOVE_MAP_TARGET = torch.tensor(np.array([cls.__MOVE_MAP[move[0]][1 if \"'\" not in move else 0] for move in cls.MOVES]), dtype=cls.__dtype, device=device)\n",
    "\n",
    "        # Initialize the scramble moves available for the cube\n",
    "        cls.SCRAMBLE_MOVES_AVAILABLE = torch.arange(len(cls.MOVES), dtype=cls.__dtype, device=device).repeat(len(cls.MOVES), 1)\n",
    "        exclude = ((torch.arange(len(cls.MOVES), device=device) + 6) % len(cls.MOVES)).unsqueeze(1)\n",
    "        cls.SCRAMBLE_MOVES_AVAILABLE = cls.SCRAMBLE_MOVES_AVAILABLE[cls.SCRAMBLE_MOVES_AVAILABLE != exclude].reshape(len(cls.MOVES), -1)\n",
    "\n",
    "        # Set the initialization flag to True\n",
    "        cls.__initialized = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def reverse_moves(moves: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Reverse the moves for the cube.\n",
    "\n",
    "        Args:\n",
    "            moves (torch.Tensor): Tensor of moves to reverse.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor of reversed moves.\n",
    "        \"\"\"\n",
    "        # Reverse the moves and apply the inverse mapping\n",
    "        return (moves + 6) % 12\n",
    "\n",
    "    def __init__(self, tensor: torch.Tensor | None = None, num_cubes: int | None = 1, device: str | None = device, use_triton: bool = ExperimentalConfig.USE_TRITON):\n",
    "        \"\"\"\n",
    "        Initialize the Cubes object.\n",
    "\n",
    "        Args:\n",
    "            tensor (torch.Tensor): Tensor representation of the cubes.\n",
    "            num_cubes (int): Number of cubes to initialize.\n",
    "            device (str): Device to use for the tensor.\n",
    "        \"\"\"\n",
    "        # Call the class initialization method\n",
    "        self.init_class(device=device)\n",
    "\n",
    "        # Record move backend setting\n",
    "        self.use_triton = use_triton\n",
    "\n",
    "        # Set the tensor for the cubes\n",
    "        if tensor is None:\n",
    "            # Check if num_cubes and device are provided\n",
    "            if num_cubes is None or device is None:\n",
    "                raise ValueError(\"Either tensor or both num_cubes and device must be provided\")\n",
    "            \n",
    "            # Create num_cubes cubes in the goal state on the specified device\n",
    "            self.reset(num_cubes=num_cubes, device=device)\n",
    "\n",
    "        else:\n",
    "            # Ignore the num_cubes and device arguments if tensor is provided\n",
    "            self.tensor = tensor\n",
    "\n",
    "            # Verify the tensor shape\n",
    "            if (self.tensor.ndim == 1):\n",
    "                self.tensor = self.tensor.unsqueeze(0)\n",
    "\n",
    "            if (self.tensor.ndim != 2) or (self.tensor.shape[1] != 6 * 3 * 3):\n",
    "                raise ValueError(\"Tensor must be of shape (num_cubes, 6 * 3 * 3)\")\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the number of cubes.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of cubes.\n",
    "        \"\"\"\n",
    "        return self.tensor.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"\n",
    "        Get a specific cube by index.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of the cube.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The cube at the specified index.\n",
    "        \"\"\"\n",
    "        return self.tensor[index]\n",
    "    \n",
    "    def __setitem__(self, index: int, value: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Set a specific cube by index.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of the cube.\n",
    "            value (torch.Tensor): New value for the cube.\n",
    "        \"\"\"\n",
    "        if value.shape != (6 * 3 * 3,):\n",
    "            raise ValueError(\"Value must be of shape (6 * 3 * 3)\")\n",
    "        self.tensor[index] = value.to(self.tensor.device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Get a string representation of the cubes.\n",
    "\n",
    "        Returns:\n",
    "            str: String representation of the cubes.\n",
    "        \"\"\"\n",
    "        return f\"Cubes(tensor={self.tensor})\"\n",
    "    \n",
    "    def to(self, device: str) -> None:\n",
    "    \n",
    "        \"\"\"\n",
    "        Move the cubes to the specified device.\n",
    "\n",
    "        Args:\n",
    "            device (str): Device to move the tensor to.\n",
    "        \"\"\"\n",
    "        self.tensor = self.tensor.to(device)\n",
    "\n",
    "    def reset(self, num_cubes: int | None = None, device: str | None = None) -> None:\n",
    "        \"\"\"\n",
    "        Reset the cubes to the goal state.\n",
    "\n",
    "        Args:\n",
    "            num_cubes (int): Number of cubes to reset.\n",
    "            device (str): Device to use for the tensor.\n",
    "        \"\"\"\n",
    "        # Set parameters to default values if not provided\n",
    "        if num_cubes is None:\n",
    "            num_cubes = self.tensor.shape[0]\n",
    "        if device is None:\n",
    "            device = self.tensor.device\n",
    "        \n",
    "        # Move the goal state to the specified device\n",
    "        self.GOAL = self.GOAL.to(device)\n",
    "\n",
    "        # Create num_cubes cubes in the goal state on the specified device\n",
    "        self.tensor = self.GOAL.unsqueeze(0).repeat(num_cubes, 1)\n",
    "\n",
    "    def is_solved(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Check if the cubes are in the solved state.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Boolean tensor indicating if each cube is solved.\n",
    "        \"\"\"\n",
    "        return (self.tensor == self.GOAL).all(dim=1)\n",
    "    \n",
    "    def move(self, moves: str | list[str] | list[list[str]] | int | list[int] | list[list[int]] | torch.Tensor) -> None:\n",
    "        \"\"\"\n",
    "        Apply a single or a sequence of moves to the cubes.\n",
    "\n",
    "        Args:\n",
    "            move (str): Move to apply.\n",
    "        \"\"\"\n",
    "        # Convert the parameter to Tensor\n",
    "\n",
    "        # str -> int\n",
    "        if isinstance(moves, str):\n",
    "            return self.move(self.MOVE_TO_INDEX[moves])\n",
    "        \n",
    "        # list[str] -> list[int]\n",
    "        elif isinstance(moves, list) and all(isinstance(move, str) for move in moves):\n",
    "            if len(moves) != self.tensor.shape[0]:\n",
    "                raise ValueError(\"Length of move list must match the number of cubes\")\n",
    "            return self.move([self.MOVE_TO_INDEX[move] for move in moves])\n",
    "        \n",
    "        # list[list[str]] -> list[list[int]]\n",
    "        elif isinstance(moves, list) and all(isinstance(step, list) and all(isinstance(move, str) for move in step) for step in moves):\n",
    "            if any(len(moves[i]) != self.tensor.shape[0] for i in range(len(moves))):\n",
    "                raise ValueError(\"Length of move list must match the number of cubes\")\n",
    "            return self.move([[self.MOVE_TO_INDEX[move] for move in round] for round in moves])\n",
    "        \n",
    "        # int -> Tensor\n",
    "        elif isinstance(moves, int):\n",
    "            moves = torch.full((self.tensor.shape[0],), moves, dtype=self.__dtype, device=self.tensor.device)\n",
    "            return self.move(moves)\n",
    "        \n",
    "        # list[int] -> Tensor\n",
    "        elif isinstance(moves, list) and all(isinstance(move, int) for move in moves):\n",
    "            if len(moves) != self.tensor.shape[0]:\n",
    "                raise ValueError(\"Length of move list must match the number of cubes\")\n",
    "            moves = torch.tensor(moves, dtype=self.__dtype, device=self.tensor.device)\n",
    "            return self.move(moves)\n",
    "        \n",
    "        # list[list[int]] -> Tensor\n",
    "        elif isinstance(moves, list) and all(isinstance(step, list) and all(isinstance(move, int) for move in step) for step in moves):\n",
    "            if any(len(moves[i]) != self.tensor.shape[0] for i in range(len(moves))):\n",
    "                raise ValueError(\"Length of move list must match the number of cubes\")\n",
    "            moves = torch.tensor(moves, dtype=self.__dtype, device=self.tensor.device)\n",
    "            return self.move(moves)\n",
    "        \n",
    "        # 2D Tensor -> Tensor\n",
    "        elif isinstance(moves, torch.Tensor) and moves.ndim == 2 and moves.shape[1] == self.tensor.shape[0]:\n",
    "            moves = moves.to(self.tensor.device)\n",
    "            for i in range(moves.shape[0]):\n",
    "                self.move(moves[i])\n",
    "            return\n",
    "        \n",
    "        # 1D Tensor -> Tensor\n",
    "        elif isinstance(moves, torch.Tensor) and moves.ndim == 1:\n",
    "            if moves.shape[0] != self.tensor.shape[0]:\n",
    "                raise ValueError(\"Length of move list must match the number of cubes\")\n",
    "            if self.use_triton and self.tensor.device.type == 'cuda':\n",
    "                # Use Triton for GPU acceleration\n",
    "                grid = (self.tensor.shape[0],)\n",
    "                self.move_triton[grid](self.tensor, moves.contiguous(), self.MOVE_MAP_SOURCE, self.MOVE_MAP_TARGET)\n",
    "            else:\n",
    "                # Use Pytorch for CPU or non-GPU acceleration\n",
    "                self.__move_torch(moves)\n",
    "            \n",
    "        # Other types\n",
    "        else:\n",
    "            raise ValueError(\"Invalid move type or shape.\")\n",
    "\n",
    "    def __move_torch(self, move: torch.Tensor) -> None:\n",
    "        \"\"\"\n",
    "        Apply a move to the cubes using PyTorch.\n",
    "\n",
    "        Args:\n",
    "            move (torch.Tensor): Tensor of moves to apply.\n",
    "        \"\"\"\n",
    "        move = move.to(self.tensor.device)\n",
    "\n",
    "        # Source indices for the move map\n",
    "        self.MOVE_MAP_SOURCE = self.MOVE_MAP_SOURCE.to(self.tensor.device)\n",
    "        source_idx = self.MOVE_MAP_SOURCE[move]\n",
    "\n",
    "        # Target indices for the move map\n",
    "        self.MOVE_MAP_TARGET = self.MOVE_MAP_TARGET.to(self.tensor.device)\n",
    "        target_idx = self.MOVE_MAP_TARGET[move]\n",
    "\n",
    "        # Batch indices for the cubes\n",
    "        batch_idx = torch.arange(self.tensor.shape[0], device=self.tensor.device).unsqueeze(1)\n",
    "\n",
    "        # Apply the move to the cubes\n",
    "        self.tensor[batch_idx, target_idx] = self.tensor[batch_idx, source_idx]\n",
    "\n",
    "    @staticmethod\n",
    "    @triton.jit\n",
    "    def move_triton(\n",
    "        cubes_ptr: torch.Tensor, \n",
    "        move_ptr: torch.Tensor,\n",
    "        move_map_source_ptr: torch.Tensor, \n",
    "        move_map_target_ptr: torch.Tensor, \n",
    "        BLOCK_SIZE: tl.constexpr = 20,\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Apply a move to the cubes using Triton.\n",
    "\n",
    "        EXPERIMENTAL: This triton kernel is not yet optimized and may not work as expected.\n",
    "        \n",
    "        NOTICE: Please ensure both cubes_ptr and move_ptr are contiguous tensors.\n",
    "\n",
    "        Args:\n",
    "            cubes (torch.Tensor): Tensor of cubes to apply the move to.\n",
    "            move (torch.Tensor): Tensor of moves to apply.\n",
    "            move_map_source (torch.Tensor): Source indices for the move map.\n",
    "            move_map_target (torch.Tensor): Target indices for the move map.\n",
    "            BLOCK_SIZE (int): Block size for Triton kernel.\n",
    "        \"\"\"\n",
    "        # Locate the cube to move\n",
    "        cube_idx = tl.program_id(0)\n",
    "        cube_offset = cube_idx * 6 * 3 * 3\n",
    "        move_offsets = tl.arange(0, 2**5)\n",
    "        mask = move_offsets < BLOCK_SIZE\n",
    "        \n",
    "        # Get the source and target indices for the move\n",
    "        move = tl.load(move_ptr + cube_idx)\n",
    "        move_map_source = tl.load(move_map_source_ptr + move * BLOCK_SIZE + move_offsets, mask=mask)\n",
    "        move_map_target = tl.load(move_map_target_ptr + move * BLOCK_SIZE + move_offsets, mask=mask)\n",
    "\n",
    "        # Move the cube\n",
    "        tmp_data = tl.load(cubes_ptr + cube_offset + move_map_source, mask=mask)\n",
    "        tl.store(cubes_ptr + cube_offset + move_map_target, tmp_data, mask=mask)\n",
    "\n",
    "    def scramble(self, scramble_length: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generate a random scramble for the cubes.\n",
    "\n",
    "        Args:\n",
    "            scramble_length (int): Length of the scramble.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor of moves for the scramble.\n",
    "        \"\"\"\n",
    "        # Generate a random scramble\n",
    "        plan = self.plan_scramble(scramble_length)\n",
    "        self.move(plan)\n",
    "\n",
    "        return plan\n",
    "\n",
    "    def plan_scramble(self, scramble_length: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generate a random scramble plan.\n",
    "\n",
    "        Args:\n",
    "            scramble_length (int): Length of the scramble.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor of moves for the scramble plan.\n",
    "        \"\"\"\n",
    "        # Move the needed variables to the device\n",
    "        self.SCRAMBLE_MOVES_AVAILABLE = self.SCRAMBLE_MOVES_AVAILABLE.to(self.tensor.device)\n",
    "\n",
    "        # Generate a random scramble plan\n",
    "        plan = torch.empty((scramble_length, self.tensor.shape[0]), dtype=self.__dtype, device=self.tensor.device)\n",
    "        for i in range(scramble_length):\n",
    "            if i == 0:\n",
    "                # The initial move is chosen randomly from the available moves\n",
    "                plan[i] = torch.randint(0, len(self.MOVES), (self.tensor.shape[0],), dtype=self.__dtype, device=self.tensor.device)\n",
    "            elif i == 1:\n",
    "                # The second move is chosen randomly from the available moves, excluding the inverse of the first move\n",
    "                plan[i] = torch.randint(0, self.SCRAMBLE_MOVES_AVAILABLE.shape[1], (self.tensor.shape[0],), dtype=self.__dtype, device=self.tensor.device)\n",
    "                plan[i] = self.SCRAMBLE_MOVES_AVAILABLE[plan[i - 1], plan[i]]\n",
    "            else:\n",
    "                generate_idx = torch.arange(self.tensor.shape[0], device=self.tensor.device)\n",
    "                while generate_idx.shape[0] > 0:\n",
    "                    # Choose a random move from the available moves, excluding the inverse of the previous move\n",
    "                    plan[i, generate_idx] = torch.randint(0, self.SCRAMBLE_MOVES_AVAILABLE.shape[1], (generate_idx.shape[0],), dtype=self.__dtype, device=self.tensor.device)\n",
    "                    plan[i, generate_idx] = self.SCRAMBLE_MOVES_AVAILABLE[plan[i - 1, generate_idx], plan[i, generate_idx]]\n",
    "\n",
    "                    # We use a range of 2 for redundancy checking\n",
    "                    # Prevent three consecutive moves from being the same -> Can be replaced with a single move\n",
    "                    # e.g. U U (U) -> U'\n",
    "                    mask1 = (plan[i, generate_idx] == plan[i - 1, generate_idx]) & (plan[i - 1, generate_idx] == plan[i - 2, generate_idx])\n",
    "\n",
    "                    # Prevent two mutually canceling moves sandwiching an opposite face move\n",
    "                    # e.g. U D (U') -> D\n",
    "                    mask2 = (self.reverse_moves(plan[i, generate_idx]) == plan[i - 2, generate_idx]) & ((plan[i, generate_idx] // 2) % 3 == (plan[i - 1, generate_idx] // 2) % 3) & (plan[i, generate_idx] % 6 != plan[i - 1, generate_idx] % 6)\n",
    "\n",
    "                    # Continue if there are no invalid moves\n",
    "                    generate_idx = generate_idx[mask1 | mask2]\n",
    "\n",
    "        return plan\n",
    "\n",
    "Cubes.init_class(device=device)  # Initialize the Cubes class with the specified device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7708e",
   "metadata": {},
   "source": [
    "## Model\n",
    "This section defines the model used to predict the last move of the scrambling path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear layer with ReLU and BatchNorm\n",
    "    \"\"\"\n",
    "    def __init__(self, input_prev, embed_dim):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_prev, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            # Due to the need to process single-sample batches in reinforcement learning,\n",
    "            # The batch normalization layer is replaced with layer normalization when reinforcement learning is enabled\n",
    "            # To maintain the result compatibility with the original EfficientCube, BatchNorm1d is used when reinforcement learning not enabled\n",
    "            nn.LayerNorm(embed_dim) if ReinforcementConfig.ENABLE else nn.BatchNorm1d(embed_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.layers(inputs)\n",
    "    \n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block with two linear layers\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            LinearBlock(embed_dim, embed_dim),\n",
    "            LinearBlock(embed_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.layers(x)\n",
    "        x += inputs # skip-connection\n",
    "        return x\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Fixed architecture following DeepCubeA.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=6*3*3*6, output_dim=len(Cubes.MOVES)):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.layers = nn.Sequential(\n",
    "            LinearBlock(input_dim, 5000),\n",
    "            LinearBlock(5000,1000),\n",
    "            ResidualBlock(1000),\n",
    "            ResidualBlock(1000),\n",
    "            ResidualBlock(1000),\n",
    "            ResidualBlock(1000),\n",
    "            nn.Linear(1000, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # int indices => float one-hot vectors\n",
    "        x = F.one_hot(inputs, num_classes=6).to(torch.float)\n",
    "        x = x.reshape(-1, self.input_dim)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "model = model.to(device)\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37d575f",
   "metadata": {},
   "source": [
    "## Training\n",
    "In this section, the model is training using real-time generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EchoDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dummy dataset to drive the training loop.\n",
    "\n",
    "    The dataset generation logic is implemented in the collate_fn function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            total_samples = TrainConfig.batch_size_per_depth * TrainConfig.num_steps\n",
    "        ):\n",
    "        self.total_samples = total_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the index only\n",
    "        return idx\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function to generate a batch of data.\n",
    "\n",
    "    Args:\n",
    "        batch (list): List of indices from the dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the input and target tensors.\n",
    "    \"\"\"\n",
    "    # Generate random cubes and moves\n",
    "    num_cubes = len(batch)\n",
    "    cubes = Cubes(num_cubes=num_cubes, device=device)\n",
    "\n",
    "    # Prepare output data\n",
    "    tensor = torch.empty(\n",
    "        (TrainConfig.max_depth * num_cubes, 6 * 3 * 3), dtype=torch.long, device=device\n",
    "    )\n",
    "\n",
    "    # Generate cubes for each depth\n",
    "    plan = cubes.plan_scramble(TrainConfig.max_depth)\n",
    "    for i in range(plan.shape[0]):\n",
    "        # Apply the moves to the cubes\n",
    "        cubes.move(plan[i])\n",
    "\n",
    "        # Store the cubes in the tensor\n",
    "        tensor[i * num_cubes : (i + 1) * num_cubes] = cubes.tensor\n",
    "\n",
    "    # Generate target moves\n",
    "    moves = plan.flatten().to(device)\n",
    "\n",
    "    return tensor, moves\n",
    "\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    EchoDataset(),\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=TrainConfig.batch_size_per_depth,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb039f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_depth_loss(pred_y: torch.Tensor, batch_y: torch.Tensor, loss_fn: callable, depth_dist: torch.Tensor, target_depth: list[int]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate the depth loss for the model.\n",
    "\n",
    "    Args:\n",
    "        pred_y (torch.Tensor): Predicted moves.\n",
    "        batch_y (torch.Tensor): Target moves.\n",
    "        depth_dist (torch.Tensor): Depth distribution.\n",
    "        target_depth (torch.Tensor | list[int]): Target depth(s).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Calculated loss.\n",
    "    \"\"\"\n",
    "    # Calculate the loss for each depth\n",
    "    losses = torch.empty((len(target_depth),), device=device)\n",
    "    for idx, depth in enumerate(target_depth):\n",
    "        # Get the mask for the current depth\n",
    "        mask = depth_dist == depth\n",
    "        \n",
    "        # Calculate the loss for the current depth\n",
    "        losses[idx] = loss_fn(pred_y[mask], batch_y[mask])\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def plot_loss_curve(losses: list[list[float]], colors: list[str], labels: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Plot the loss curve.\n",
    "    \n",
    "    Args:\n",
    "        losses (list[list[float]]): List of loss values.\n",
    "        colors (list[str]): List of colors for each curve.\n",
    "        labels (list[str]): List of labels for each curve.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    for loss, color, label in zip(losses, colors, labels):\n",
    "        ax.plot(loss, color=color, label=label)\n",
    "    ax.set_xlabel(\"Steps\")\n",
    "    ax.set_ylabel(\"Cross-entropy loss\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc5682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: Model, dataloader: torch.utils.data.DataLoader) -> Model:\n",
    "    \"\"\"\n",
    "    Train the model on the dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (Model): The model to be trained.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader for the training data.\n",
    "    \"\"\"\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=TrainConfig.learning_rate)\n",
    "\n",
    "    # Data generator\n",
    "    loop = tqdm(dataloader, unit=\"step\")\n",
    "\n",
    "    # Training losses\n",
    "    losses = []\n",
    "    \n",
    "    # Loss for each depth\n",
    "    depth_loss = [[] for _ in range(len(TrainConfig.target_depth))] if TrainConfig.SHOW_DEPTH_LOSS else []\n",
    "\n",
    "    # Depth distribution\n",
    "    depth_dist = torch.arange(1, TrainConfig.max_depth+1, device=device).repeat_interleave(TrainConfig.batch_size_per_depth)\n",
    "\n",
    "    # Context manager for mixed precision training\n",
    "    ctx = torch.amp.autocast('cuda', dtype=torch.float16) if TrainConfig.ENABLE_FP16 else nullcontext()\n",
    "    scaler = torch.GradScaler(enabled=TrainConfig.ENABLE_FP16)\n",
    "\n",
    "    for step, (batch_x, batch_y) in enumerate(loop):\n",
    "        # Adjust data shape for the model\n",
    "        batch_x, batch_y = batch_x.reshape(-1, 54).to(device), batch_y.reshape(-1).to(device)\n",
    "\n",
    "        # Training step\n",
    "        with ctx:\n",
    "            pred_y = model(batch_x)\n",
    "            loss = loss_fn(pred_y, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update losses and progress bar\n",
    "        losses.append(loss.item())\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Record the loss for each depth\n",
    "        if TrainConfig.SHOW_DEPTH_LOSS:\n",
    "            depth_loss_tensor = calc_depth_loss(pred_y, batch_y, loss_fn, depth_dist, TrainConfig.target_depth)\n",
    "            for i in range(len(TrainConfig.target_depth)):\n",
    "                depth_loss[i].append(depth_loss_tensor[i].item())\n",
    "\n",
    "        # Plot the loss curve\n",
    "        # Plot the loss curve every INTERVAL_PLOT steps\n",
    "        if TrainConfig.INTERVAL_PLOT and (step+1) % TrainConfig.INTERVAL_PLOT == 0:\n",
    "            clear_output()\n",
    "            plot_loss_curve(\n",
    "                [losses, *depth_loss],\n",
    "                [\"k\", *TrainConfig.depth_colors],\n",
    "                [\"Total loss\", *[f\"Depth {depth}\" for depth in TrainConfig.target_depth]]\n",
    "            )\n",
    "\n",
    "        # Save the model\n",
    "        # Save the model every INTERVAL_SAVE steps\n",
    "        if TrainConfig.INTERVAL_SAVE and (step+1) % TrainConfig.INTERVAL_SAVE == 0:\n",
    "            torch.save(model.state_dict(), f\"{step+1}steps.pth\")\n",
    "            print(\"Model saved.\")\n",
    "\n",
    "    print(f\"Trained on data equivalent to {TrainConfig.batch_size_per_depth * TrainConfig.num_steps} solves.\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "if TrainConfig.SAVED_MODEL is None:\n",
    "    # Train the model if no saved model is provided\n",
    "    model = train(model, dataloader)\n",
    "else:\n",
    "    # Load the saved model if provided\n",
    "    model.load_state_dict(torch.load(TrainConfig.SAVED_MODEL))\n",
    "    print(f\"Model loaded from {TrainConfig.SAVED_MODEL}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516ad15",
   "metadata": {},
   "source": [
    "## Inference\n",
    "We test and comapare our model on the DeepCubeA dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e0781e",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "Retrieve the data set from GitHub if not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d36b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the DeepCubeA repository if not already present\n",
    "if \"DeepCubeA\" != os.getcwd().split(\"/\")[-1]:\n",
    "    if not os.path.exists(\"DeepCubeA\"):\n",
    "        !git clone -q https://github.com/forestagostinelli/DeepCubeA\n",
    "    %cd ./DeepCubeA/\n",
    "\n",
    "# Load the data set\n",
    "print('### Optimal Solver ###')\n",
    "filename = 'data/cube3/test/data_0.pkl'\n",
    "with open(filename, 'rb') as f:\n",
    "    result_Optimal = pickle.load(f)\n",
    "\n",
    "    print(result_Optimal.keys())\n",
    "    result_Optimal[\"solution_lengths\"] = [len(s) for s in result_Optimal[\"solutions\"]]\n",
    "    result_Optimal[\"solution_lengths_count\"] = {\n",
    "        i: result_Optimal[\"solution_lengths\"].count(i)\n",
    "        for i in range(min(result_Optimal[\"solution_lengths\"]), max(result_Optimal[\"solution_lengths\"]))\n",
    "    }\n",
    "\n",
    "    print('No. of cases:', len(result_Optimal[\"solution_lengths\"]))\n",
    "\n",
    "# Load the result of DeepCubeA for comparison\n",
    "print('\\n### DeepCubeA ###')\n",
    "filename = 'results/cube3/results.pkl'\n",
    "with open(filename, 'rb') as f:\n",
    "    result_DeepCubeA = pickle.load(f)\n",
    "\n",
    "    print(result_DeepCubeA.keys())\n",
    "    result_DeepCubeA[\"solution_lengths\"] = [len(s) for s in result_DeepCubeA[\"solutions\"]]\n",
    "    result_DeepCubeA[\"solution_lengths_count\"] = {\n",
    "        i: result_DeepCubeA[\"solution_lengths\"].count(i)\n",
    "        for i in range(min(result_DeepCubeA[\"solution_lengths\"]), max(result_DeepCubeA[\"solution_lengths\"]))\n",
    "    }\n",
    "\n",
    "    print('No. of cases:', len(result_DeepCubeA[\"solution_lengths\"]))\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert optimal solutions to test scrambles\n",
    "def solution2scramble(solution):\n",
    "    return [m[0] if m[1] == -1 else m[0] + \"'\" for m in solution[::-1]]\n",
    "\n",
    "test_scrambles = [solution2scramble(s) for s in result_Optimal[\"solutions\"]]\n",
    "\n",
    "print(f\"\"\"Example:\\n{result_Optimal[\"solutions\"][0]}\\n-> {test_scrambles[0]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013b36e",
   "metadata": {},
   "source": [
    "### Beam Search\n",
    "We use beam search to expand the traced set of possible solutions, which does not guarantee to give a solution but effiectively improved the probability of finding one (and the one as optimial as possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def beam_search(\n",
    "    cubes: Cubes, \n",
    "    model: Model, \n",
    "    beam_width: int = SearchConfig.beam_width, \n",
    "    max_depth: int = SearchConfig.max_depth,\n",
    "    skip_redundant_moves: bool = True\n",
    "    ) -> list[None | dict]:\n",
    "    \"\"\"\n",
    "    Best-first beam search for the optimal solution.\n",
    "    \n",
    "    Args:\n",
    "        cubes (Cubes): The cubes to be solved.\n",
    "        model (Model): The model to be used for prediction.\n",
    "        beam_width (int): The width of the beam search.\n",
    "        max_depth (int): The maximum depth of the search.\n",
    "        skip_redundant_moves (bool): Whether to skip redundant moves.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The predicted moves for the solution.\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare the data structure for the beam search\n",
    "    candidates = torch.empty((len(cubes), beam_width, 6 * 3 * 3), dtype=torch.long, device=cubes.tensor.device)\n",
    "    candidates[:, 0] = cubes.tensor\n",
    "    candidate_paths = torch.empty((len(cubes), beam_width, max_depth), dtype=torch.long, device=candidates.device)\n",
    "    candidate_log_probs = torch.zeros((len(cubes), beam_width), dtype=torch.float, device=candidates.device)\n",
    "    candidate_cube_idx = torch.arange(len(cubes), device=candidates.device).unsqueeze(1).expand(-1, beam_width)\n",
    "\n",
    "    # Prepare the data structure for output\n",
    "    output = [None] * len(cubes)\n",
    "    time_0 = time.time()\n",
    "\n",
    "    # Initialize the beam search\n",
    "    ctx = torch.amp.autocast('cuda', dtype=torch.float16) if TrainConfig.ENABLE_FP16 else nullcontext()\n",
    "    for depth in range(max_depth):\n",
    "        # Select the candidates for the current depth\n",
    "        candidate_len = min(beam_width, len(Cubes.MOVES)**depth)\n",
    "        active_candidates = candidates[:, :candidate_len].reshape(-1, 6 * 3 * 3)\n",
    "        active_candidate_paths = candidate_paths[:, :candidate_len, :depth].reshape(candidate_paths.shape[0] * candidate_len, depth)\n",
    "        active_candidate_cube_idx = candidate_cube_idx[:, :candidate_len].flatten()\n",
    "\n",
    "        # Check if the candidates are already solved\n",
    "        solved_mask = Cubes(active_candidates).is_solved()\n",
    "        if solved_mask.any():\n",
    "            # If any of the candidates are solved, update the output\n",
    "            solved_active_candidate_idx = torch.arange(solved_mask.shape[0], device=candidates.device)[solved_mask]\n",
    "            solved_cube_idx = active_candidate_cube_idx[solved_mask]\n",
    "            time_duration = time.time() - time_0\n",
    "            for i in range(solved_active_candidate_idx.shape[0]):\n",
    "                solved_idx = solved_active_candidate_idx[i]\n",
    "                cube_idx = solved_cube_idx[i]\n",
    "                if output[cube_idx] is None:\n",
    "                    output[cube_idx] = {\n",
    "                        \"solution\": active_candidate_paths[solved_idx].cpu().numpy().tolist(),\n",
    "                        \"time\": time_duration,\n",
    "                        \"depth\": depth,\n",
    "                    }\n",
    "\n",
    "            # If all cubes are solved, break the loop\n",
    "            solved_cube_idx = solved_cube_idx.unique()\n",
    "            if solved_cube_idx.shape[0] == candidates.shape[0]:\n",
    "                break\n",
    "            \n",
    "            # Remove the solved cubes from the candidates\n",
    "            candidate_mask = ~solved_mask.reshape(candidates.shape[0], -1).any(dim=1)\n",
    "            candidates = candidates[candidate_mask]\n",
    "            candidate_paths = candidate_paths[candidate_mask]\n",
    "            candidate_log_probs = candidate_log_probs[candidate_mask]\n",
    "            candidate_cube_idx = candidate_cube_idx[candidate_mask]\n",
    "\n",
    "            # Regenerate the active candidates\n",
    "            active_candidates = candidates[:, :candidate_len].reshape(-1, 6 * 3 * 3)\n",
    "            active_candidate_paths = candidate_paths[:, :candidate_len, :depth].reshape(candidate_paths.shape[0] * candidate_len, depth)\n",
    "            active_candidate_cube_idx = candidate_cube_idx[:, :candidate_len].flatten()\n",
    "            \n",
    "        with ctx:\n",
    "            # Get the predictions from the model\n",
    "            pred = model(active_candidates).reshape(candidates.shape[0], candidate_len, -1)\n",
    "\n",
    "            # Calculate the log probabilities\n",
    "            log_probs = F.log_softmax(pred, dim=-1)\n",
    "\n",
    "        # Filter the log probabilities based on the active candidates\n",
    "        active_candidate_log_probs = candidate_log_probs[:, :candidate_len]\n",
    "        next_move_log_probs = active_candidate_log_probs.unsqueeze(-1) + log_probs\n",
    "        next_move_log_probs = next_move_log_probs.reshape(next_move_log_probs.shape[0], -1)\n",
    "        next_moves = torch.arange(log_probs.shape[-1], device=candidates.device).repeat(candidate_len).unsqueeze(0).expand(next_move_log_probs.shape[0], -1)\n",
    "        next_move_candidate_idx = torch.arange(candidate_len, device=candidates.device).unsqueeze(-1).repeat(1, log_probs.shape[-1]).flatten().unsqueeze(0).expand(next_move_log_probs.shape[0], -1)\n",
    "\n",
    "        # Remove redundant moves if specified (1 steps forward)\n",
    "        if skip_redundant_moves and depth > 0:\n",
    "            # Build the mask for redundant moves\n",
    "            last_moves = active_candidate_paths[:, -1].reshape(candidate_paths.shape[0], candidate_len, 1).expand(-1, -1, log_probs.shape[-1]).reshape(next_move_log_probs.shape[0], -1)\n",
    "            assert last_moves.shape == next_moves.shape, f\"last_moves: {last_moves.shape}, next_moves: {next_moves.shape}\"\n",
    "            mask = Cubes.reverse_moves(last_moves) == next_moves\n",
    "            next_move_log_probs = next_move_log_probs.masked_fill(mask, -float(\"inf\"))\n",
    "\n",
    "        # Remove redundant moves if specified (2 steps forward)\n",
    "        if skip_redundant_moves and depth > 1:\n",
    "            # Prevent three consecutive moves from being the same -> Can be replaced with a single move\n",
    "            # e.g. U U (U) -> U'\n",
    "            second_last_moves = active_candidate_paths[:, -2].reshape(candidate_paths.shape[0], candidate_len, 1).expand(-1, -1, log_probs.shape[-1]).reshape(next_move_log_probs.shape[0], -1)\n",
    "            mask1 = (next_moves == last_moves) & (last_moves == second_last_moves)\n",
    "\n",
    "            # Prevent two mutually canceling moves sandwiching an opposite face move\n",
    "            # e.g. U D (U') -> D\n",
    "            mask2 = (Cubes.reverse_moves(next_moves) == second_last_moves) & ((next_moves // 2) % 3 == (last_moves // 2) % 3) & (next_moves % 6 != last_moves % 6)\n",
    "            mask = mask1 | mask2\n",
    "\n",
    "            # Apply the mask to the log probabilities\n",
    "            next_move_log_probs = next_move_log_probs.masked_fill(mask, -float(\"inf\"))\n",
    "        \n",
    "        # Filter next moves based on probabilities\n",
    "        sorted_next_move_log_probs_idx = torch.argsort(next_move_log_probs, dim=-1, descending=True)[:, :beam_width]\n",
    "        next_move_log_probs = next_move_log_probs.gather(1, sorted_next_move_log_probs_idx)\n",
    "        next_moves = next_moves.gather(1, sorted_next_move_log_probs_idx)\n",
    "        next_move_candidate_idx = next_move_candidate_idx.gather(1, sorted_next_move_log_probs_idx)\n",
    "\n",
    "        # Update the candidates with the next moves\n",
    "        candidates[:, :next_move_candidate_idx.shape[1]] = candidates.gather(1, next_move_candidate_idx.unsqueeze(-1).expand(-1, -1, 6 * 3 * 3))\n",
    "        candidate_paths[:, :next_move_candidate_idx.shape[1], :depth] = active_candidate_paths.reshape(candidate_paths.shape[0], candidate_len, depth).gather(1, next_move_candidate_idx.unsqueeze(-1).expand(-1, -1, depth))\n",
    "        candidate_log_probs[:, :next_move_candidate_idx.shape[1]] = next_move_log_probs\n",
    "        \n",
    "        # Apply the next moves to the candidates\n",
    "        candidate_paths[:, :next_move_candidate_idx.shape[1], depth] = next_moves\n",
    "        temp_cubes = Cubes(candidates[:, :next_move_candidate_idx.shape[1]].reshape(-1, 6 * 3 * 3))\n",
    "        temp_cubes.move(Cubes.reverse_moves(next_moves.flatten()))\n",
    "        candidates[:, :next_move_candidate_idx.shape[1]] = temp_cubes.tensor.reshape(candidates.shape[0], -1, 6 * 3 * 3).clone()\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31af6f",
   "metadata": {},
   "source": [
    "### Solve\n",
    "Use beam search to solve the given test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed28ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preheat the beam search with a test scramble\n",
    "cube = Cubes(num_cubes=1)\n",
    "cube.move([[move] for move in test_scrambles[0]])\n",
    "output = beam_search(cube, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d605b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the result dictionary\n",
    "result_ours = {\n",
    "    \"solutions\":[],\n",
    "    \"num_nodes_generated\":[],\n",
    "    \"times\":[]\n",
    "}\n",
    "\n",
    "# Solve the test scrambles using beam search\n",
    "for scramble in tqdm(test_scrambles, position=0, desc=\"Solving test scrambles\"):\n",
    "    # Initialize the cubes with the scramble\n",
    "    cubes = Cubes(num_cubes=1, device=device)\n",
    "    cubes.move([[move] for move in scramble])\n",
    "\n",
    "    # Perform beam search to find the solution\n",
    "    output = beam_search(cubes, model, beam_width=SearchConfig.beam_width, max_depth=SearchConfig.max_depth)[0]\n",
    "\n",
    "    # Store the results\n",
    "    if output is None:\n",
    "        result_ours[\"solutions\"].append(None)\n",
    "    else:\n",
    "        result_ours[\"solutions\"].append(output[\"solution\"])\n",
    "        result_ours[\"num_nodes_generated\"].append(sum([min(SearchConfig.beam_width, len(Cubes.MOVES)**i) for i in range(output[\"depth\"])])*len(Cubes.MOVES))\n",
    "        result_ours[\"times\"].append(output[\"time\"])\n",
    "\n",
    "# Get statistics of the results\n",
    "result_ours['solution_lengths'] = [len(solution) for solution in result_ours['solutions'] if solution]\n",
    "result_ours['solution_lengths_count'] = Counter(result_ours['solution_lengths'])\n",
    "\n",
    "f\"Successfully solved {len(result_ours['times'])} cases out of {len(result_ours['solutions'])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize result\n",
    "fig, ax = plt.subplots(2, 3, figsize=(16, 9))\n",
    "ax = ax.ravel()\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[1].set_xlabel(\"Number of nodes\")\n",
    "\n",
    "key_to_text = {\n",
    "    \"solution_lengths\":    \"Solution lengths\",\n",
    "    'num_nodes_generated': \"Number of nodes\",\n",
    "    \"times\":               \"Time (s)\",\n",
    "}\n",
    "\n",
    "for index, k in enumerate([\"solution_lengths\", \"num_nodes_generated\", \"times\"]):\n",
    "    v = result_ours[k]\n",
    "    if k==\"solution_lengths\":\n",
    "        v_count = result_ours['solution_lengths_count']\n",
    "        ax[index].bar(v_count.keys(), v_count.values(), width=1.0)\n",
    "    else:\n",
    "        ax[index].hist(v)\n",
    "    ax[index].axvline(np.mean(v), color=\"#00ffff\", label=f\"mean={np.mean(v):.3f}\")\n",
    "    ax[index].set_xlabel(key_to_text[k])\n",
    "    ax[index].legend()\n",
    "\n",
    "for index, (key_x, key_y) in enumerate([(\"solution_lengths\", \"num_nodes_generated\"), (\"num_nodes_generated\", \"times\"), (\"times\", \"solution_lengths\")]):\n",
    "    index += 3\n",
    "    x, y = [result_ours[k] for k in [key_x, key_y]]\n",
    "    ax[index].set_xlabel(key_to_text[key_x])\n",
    "    ax[index].set_ylabel(key_to_text[key_y])\n",
    "\n",
    "    x_range = np.linspace(0, max(x), 100)\n",
    "    coef = np.mean(np.squeeze(np.array(y) / np.array(x)))\n",
    "    ax[index].plot(x_range, x_range * coef, label=f\"slope={coef:.6f}\", color=\"#00ffff\")\n",
    "    ax[index].scatter(x, y)\n",
    "    ax[index].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc9c05",
   "metadata": {},
   "source": [
    "## Compare to DeepCubeA\n",
    "Number of nodes vs. solution length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aaf389",
   "metadata": {},
   "outputs": [],
   "source": [
    "left, width = 0.12, 0.75\n",
    "bottom, height = 0.1, 0.75\n",
    "spacing = 0.0\n",
    "\n",
    "rect_scatter = [left, bottom, width, height]\n",
    "rect_histx = [left, bottom + height, width, 0.1]\n",
    "rect_histy = [left + width, bottom, 0.1, height]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_axes(rect_scatter)\n",
    "ax.set_xlabel(\"Number of nodes\")\n",
    "ax.set_ylabel(\"Solution length\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax_histx = fig.add_axes(rect_histx, sharex=ax)\n",
    "ax_histy = fig.add_axes(rect_histy, sharey=ax)\n",
    "ax_histx.set_ylabel(\"Frequency\")\n",
    "ax_histy.set_xlabel(\"Frequency\")\n",
    "ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
    "ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "ax.set_ylim(15, max(result_ours['solution_lengths_count']))\n",
    "ax_histy.set_ylim(15, max(result_ours['solution_lengths_count']))\n",
    "\n",
    "xmin, xmax = 2.5, 8.5\n",
    "ax.set_xlim(10**xmin, 10**xmax)\n",
    "ax_histx.set_xlim(10**xmin, 10**xmax)\n",
    "bins_x = np.logspace(xmin, xmax, 100)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "key_x, key_y = \"num_nodes_generated\", \"solution_lengths\"\n",
    "\n",
    "for k, data in [(\"Optimal\", result_Optimal), (\"DeepCubeA\", result_DeepCubeA), (\"Ours\", result_ours)]:\n",
    "    x, y = data[key_x], data[key_y]\n",
    "    ax.scatter(x, y, s=10, alpha=0.3)\n",
    "    ax_histx.hist(x, bins=bins_x, alpha=0.7)\n",
    "\n",
    "for index, data in enumerate([result_Optimal, result_DeepCubeA, result_ours]):\n",
    "    data = data[\"solution_lengths_count\"]\n",
    "    ax_histy.barh(list(data.keys()), list(data.values()), height=1, alpha=0.7)\n",
    "\n",
    "ax_histy.axhline(np.mean(result_ours[key_y]), ls=\"--\", color=\"#EB4275\")\n",
    "ax.axhline(np.mean(result_ours[key_y]), ls=\"--\", color=\"#EB4275\")\n",
    "\n",
    "ax.plot(np.mean(result_Optimal[key_x]), np.mean(result_Optimal[key_y]),     \"x\", markersize=12, label=\"Optimal\")\n",
    "ax.plot(np.mean(result_DeepCubeA[key_x]), np.mean(result_DeepCubeA[key_y]), \"x\", markersize=12, label=\"DeepCubeA\")\n",
    "ax.plot(np.mean(result_ours[key_x]), np.mean(result_ours[key_y]),           \"x\", markersize=12, label=\"Ours\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237bc3ed",
   "metadata": {},
   "source": [
    "## Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdac805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce(\n",
    "    model: Model,\n",
    "    depths: int | list[int]= ReinforcementConfig.depths,\n",
    "    batch_size: int = ReinforcementConfig.batch_size,\n",
    "    num_steps: int = ReinforcementConfig.num_steps,\n",
    "    learning_rate: float = ReinforcementConfig.learning_rate,\n",
    "    max_depth: int = ReinforcementConfig.max_depth,\n",
    "    epsilon: float = ReinforcementConfig.epsilon,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reinforcement learning training loop.\n",
    "\n",
    "    Args:\n",
    "        model (Model): The model to be trained.\n",
    "        depths (int | list[int]): The depth(s) to train on.\n",
    "        batch_size (int): The batch size for training.\n",
    "        num_steps (int): The number of training steps.\n",
    "        learning_rate (float): The learning rate for the optimizer.\n",
    "        max_depth (int): The maximum depth for the training.\n",
    "    \"\"\"\n",
    "    # Convert the depths to a list if it's an integer\n",
    "    depths = [depths] if isinstance(depths, int) else depths\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    with torch.amp.autocast('cuda', dtype=torch.float16) if ReinforcementConfig.ENABLE_FP16 else nullcontext():\n",
    "        scaler = torch.GradScaler(enabled=ReinforcementConfig.ENABLE_FP16)\n",
    "\n",
    "        loop = tqdm(range(num_steps), unit=\"step\", position=0)\n",
    "        for step in loop:\n",
    "            # Randomly select a depth\n",
    "            scramble = random.choice(depths)\n",
    "            loop.set_postfix(scramble=scramble)\n",
    "\n",
    "            # Generate a batch of cubes\n",
    "            cubes = Cubes(num_cubes=batch_size, device=device)\n",
    "            cubes.scramble(scramble)\n",
    "\n",
    "            # Prepare the data structure for the batch\n",
    "            batch_log_probs = torch.empty((batch_size, max_depth), dtype=torch.float, device=device)\n",
    "            solution_lengths = torch.full((batch_size,), max_depth+1, dtype=torch.float, device=device)\n",
    "            cube_idx = torch.arange(batch_size, device=device)\n",
    "            move_cache = torch.empty((batch_size, max_depth), dtype=torch.long, device=device)\n",
    "\n",
    "            # Solve the cubes\n",
    "            inner_loop = tqdm(range(max_depth), unit=\"depth\", position=1, leave=False, disable=True)\n",
    "            inner_loop.set_postfix(cubes=batch_size)\n",
    "            for depth in inner_loop:\n",
    "                # Get the predictions from the model\n",
    "                pred = model(cubes.tensor)\n",
    "\n",
    "                # Filter redundant moves\n",
    "                if depth > 0:\n",
    "                    # Build the mask for redundant moves\n",
    "                    last_moves = move_cache[:, depth - 1].unsqueeze(-1)\n",
    "                    mask = torch.zeros_like(pred, dtype=torch.bool)\n",
    "                    mask = mask.scatter(1, Cubes.reverse_moves(last_moves), True)\n",
    "\n",
    "                    # Apply the mask to the predictions\n",
    "                    pred = pred.masked_fill(mask, -float(\"inf\"))\n",
    "\n",
    "                probs = F.softmax(pred, dim=-1)\n",
    "                log_probs = F.log_softmax(pred, dim=-1)\n",
    "\n",
    "                # Epsilon-greedy exploration\n",
    "                if random.random() < epsilon:\n",
    "                    if depth == 0:\n",
    "                        moves = torch.randint(0, len(Cubes.MOVES), (len(cubes),), dtype=torch.long, device=device)\n",
    "                    else:\n",
    "                        Cubes.SCRAMBLE_MOVES_AVAILABLE = Cubes.SCRAMBLE_MOVES_AVAILABLE.to(cubes.tensor.device)\n",
    "                        moves = torch.randint(0, Cubes.SCRAMBLE_MOVES_AVAILABLE.shape[1], (len(cubes),), dtype=torch.long, device=device)\n",
    "                        moves = Cubes.SCRAMBLE_MOVES_AVAILABLE[move_cache[:, depth - 1], moves]\n",
    "                else:\n",
    "                    moves = probs.multinomial(1).squeeze(1)\n",
    "\n",
    "                # Save the log probabilities for gradient calculation\n",
    "                log_probs = log_probs.gather(1, moves.unsqueeze(1)).squeeze(1)\n",
    "                batch_log_probs[cube_idx, depth] = log_probs\n",
    "\n",
    "                # Apply the moves to the cubes\n",
    "                cubes = Cubes(cubes.tensor.clone())\n",
    "                cubes.move(Cubes.reverse_moves(moves))\n",
    "                move_cache[:, depth] = moves\n",
    "\n",
    "                # Check if any of the cubes are solved\n",
    "                solved_mask = cubes.is_solved()\n",
    "                if solved_mask.any():\n",
    "                    print(f\"depth={depth} solved_mask={solved_mask}\")\n",
    "                    # If any of the cubes are solved, update the solution lengths\n",
    "                    solution_lengths[cube_idx[solved_mask]] = depth + 1\n",
    "\n",
    "                    # Remove the solved cubes from the batch\n",
    "                    cubes = Cubes(cubes.tensor[~solved_mask])\n",
    "                    cube_idx = cube_idx[~solved_mask]\n",
    "                    move_cache = move_cache[~solved_mask]\n",
    "\n",
    "                    # Update tqdm progress bar\n",
    "                    inner_loop.set_postfix(cubes=cube_idx.shape[0])\n",
    "\n",
    "                    # If all cubes are solved, break the loop\n",
    "                    if cube_idx.shape[0] == 0:\n",
    "                        break\n",
    "\n",
    "            # If no cubes are solved, skip the batch\n",
    "            if cube_idx.shape[0] == batch_size:\n",
    "                continue\n",
    "\n",
    "            # Calculate the rewards\n",
    "            solved_mask = solution_lengths <= max_depth\n",
    "            rewards = torch.zeros_like(solution_lengths, dtype=torch.float, device=device)\n",
    "            rewards[solved_mask] = 1.0 - (solution_lengths[solved_mask] / max_depth)\n",
    "            # rewards[~solved_mask] = -0.1\n",
    "            rewards = rewards - rewards.mean()\n",
    "            # rewards = rewards / (torch.std(solution_lengths) + 1e-8)\n",
    "            # rewards = rewards / (rewards.max() + 1e-8)\n",
    "            rewards = rewards.unsqueeze(1)\n",
    "\n",
    "            # Calculate the loss\n",
    "            losses = []\n",
    "            for i in range(batch_log_probs.shape[0]):\n",
    "                seq_len = min(int(solution_lengths[i].item()), batch_log_probs.shape[1])\n",
    "                reward = rewards[i].expand(seq_len)\n",
    "                log_probs = batch_log_probs[i, :seq_len]\n",
    "                loss = -torch.sum(log_probs * reward)\n",
    "                losses.append(loss)\n",
    "            loss = torch.stack(losses).mean()\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            with torch.autograd.set_detect_anomaly(True):\n",
    "                scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Reinforcement learning training loop\n",
    "if ReinforcementConfig.ENABLE:\n",
    "    print(\"Reinforcement learning training loop\")\n",
    "    model = reinforce(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d3f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip the cell if reinforcement learning is not enabled\n",
    "if not ReinforcementConfig.ENABLE:\n",
    "    print(\"Reinforcement learning is not enabled. Skipping post-reinforcement evaluation.\")\n",
    "else:\n",
    "\n",
    "    # Initialize the result dictionary\n",
    "    result_ours = {\n",
    "        \"solutions\":[],\n",
    "        \"num_nodes_generated\":[],\n",
    "        \"times\":[]\n",
    "    }\n",
    "\n",
    "    # Solve the test scrambles using beam search\n",
    "    for scramble in tqdm(test_scrambles, position=0, desc=\"Solving test scrambles\"):\n",
    "        # Initialize the cubes with the scramble\n",
    "        cubes = Cubes(num_cubes=1, device=device)\n",
    "        cubes.move([[move] for move in scramble])\n",
    "\n",
    "        # Perform beam search to find the solution\n",
    "        output = beam_search(cubes, model, beam_width=SearchConfig.beam_width, max_depth=SearchConfig.max_depth)[0]\n",
    "\n",
    "        # Store the results\n",
    "        if output is None:\n",
    "            result_ours[\"solutions\"].append(None)\n",
    "        else:\n",
    "            result_ours[\"solutions\"].append(output[\"solution\"])\n",
    "            result_ours[\"num_nodes_generated\"].append(sum([min(SearchConfig.beam_width, len(Cubes.MOVES)**i) for i in range(output[\"depth\"])])*len(Cubes.MOVES))\n",
    "            result_ours[\"times\"].append(output[\"time\"])\n",
    "\n",
    "    # Get statistics of the results\n",
    "    result_ours['solution_lengths'] = [len(solution) for solution in result_ours['solutions'] if solution]\n",
    "    result_ours['solution_lengths_count'] = Counter(result_ours['solution_lengths'])\n",
    "\n",
    "    f\"Successfully solved {len(result_ours['times'])} cases out of {len(result_ours['solutions'])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada89928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip the cell if reinforcement learning is not enabled\n",
    "if not ReinforcementConfig.ENABLE:\n",
    "    print(\"Reinforcement learning is not enabled. Skipping post-reinforcement evaluation.\")\n",
    "else:\n",
    "\n",
    "    # Visualize result\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(16, 9))\n",
    "    ax = ax.ravel()\n",
    "    ax[0].set_ylabel(\"Frequency\")\n",
    "    ax[1].set_xlabel(\"Number of nodes\")\n",
    "\n",
    "    key_to_text = {\n",
    "        \"solution_lengths\":    \"Solution lengths\",\n",
    "        'num_nodes_generated': \"Number of nodes\",\n",
    "        \"times\":               \"Time (s)\",\n",
    "    }\n",
    "\n",
    "    for index, k in enumerate([\"solution_lengths\", \"num_nodes_generated\", \"times\"]):\n",
    "        v = result_ours[k]\n",
    "        if k==\"solution_lengths\":\n",
    "            v_count = result_ours['solution_lengths_count']\n",
    "            ax[index].bar(v_count.keys(), v_count.values(), width=1.0)\n",
    "        else:\n",
    "            ax[index].hist(v)\n",
    "        ax[index].axvline(np.mean(v), color=\"#00ffff\", label=f\"mean={np.mean(v):.3f}\")\n",
    "        ax[index].set_xlabel(key_to_text[k])\n",
    "        ax[index].legend()\n",
    "\n",
    "    for index, (key_x, key_y) in enumerate([(\"solution_lengths\", \"num_nodes_generated\"), (\"num_nodes_generated\", \"times\"), (\"times\", \"solution_lengths\")]):\n",
    "        index += 3\n",
    "        x, y = [result_ours[k] for k in [key_x, key_y]]\n",
    "        ax[index].set_xlabel(key_to_text[key_x])\n",
    "        ax[index].set_ylabel(key_to_text[key_y])\n",
    "\n",
    "        x_range = np.linspace(0, max(x), 100)\n",
    "        coef = np.mean(np.squeeze(np.array(y) / np.array(x)))\n",
    "        ax[index].plot(x_range, x_range * coef, label=f\"slope={coef:.6f}\", color=\"#00ffff\")\n",
    "        ax[index].scatter(x, y)\n",
    "        ax[index].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967889e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip the cell if reinforcement learning is not enabled\n",
    "if not ReinforcementConfig.ENABLE:\n",
    "    print(\"Reinforcement learning is not enabled. Skipping post-reinforcement evaluation.\")\n",
    "else:\n",
    "\n",
    "    left, width = 0.12, 0.75\n",
    "    bottom, height = 0.1, 0.75\n",
    "    spacing = 0.0\n",
    "\n",
    "    rect_scatter = [left, bottom, width, height]\n",
    "    rect_histx = [left, bottom + height, width, 0.1]\n",
    "    rect_histy = [left + width, bottom, 0.1, height]\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_axes(rect_scatter)\n",
    "    ax.set_xlabel(\"Number of nodes\")\n",
    "    ax.set_ylabel(\"Solution length\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax_histx = fig.add_axes(rect_histx, sharex=ax)\n",
    "    ax_histy = fig.add_axes(rect_histy, sharey=ax)\n",
    "    ax_histx.set_ylabel(\"Frequency\")\n",
    "    ax_histy.set_xlabel(\"Frequency\")\n",
    "    ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
    "    ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "    ax.set_ylim(15, max(result_ours['solution_lengths_count']))\n",
    "    ax_histy.set_ylim(15, max(result_ours['solution_lengths_count']))\n",
    "\n",
    "    xmin, xmax = 2.5, 8.5\n",
    "    ax.set_xlim(10**xmin, 10**xmax)\n",
    "    ax_histx.set_xlim(10**xmin, 10**xmax)\n",
    "    bins_x = np.logspace(xmin, xmax, 100)\n",
    "\n",
    "    ################################################################################\n",
    "\n",
    "    key_x, key_y = \"num_nodes_generated\", \"solution_lengths\"\n",
    "\n",
    "    for k, data in [(\"Optimal\", result_Optimal), (\"DeepCubeA\", result_DeepCubeA), (\"Ours\", result_ours)]:\n",
    "        x, y = data[key_x], data[key_y]\n",
    "        ax.scatter(x, y, s=10, alpha=0.3)\n",
    "        ax_histx.hist(x, bins=bins_x, alpha=0.7)\n",
    "\n",
    "    for index, data in enumerate([result_Optimal, result_DeepCubeA, result_ours]):\n",
    "        data = data[\"solution_lengths_count\"]\n",
    "        ax_histy.barh(list(data.keys()), list(data.values()), height=1, alpha=0.7)\n",
    "\n",
    "    ax_histy.axhline(np.mean(result_ours[key_y]), ls=\"--\", color=\"#EB4275\")\n",
    "    ax.axhline(np.mean(result_ours[key_y]), ls=\"--\", color=\"#EB4275\")\n",
    "\n",
    "    ax.plot(np.mean(result_Optimal[key_x]), np.mean(result_Optimal[key_y]),     \"x\", markersize=12, label=\"Optimal\")\n",
    "    ax.plot(np.mean(result_DeepCubeA[key_x]), np.mean(result_DeepCubeA[key_y]), \"x\", markersize=12, label=\"DeepCubeA\")\n",
    "    ax.plot(np.mean(result_ours[key_x]), np.mean(result_ours[key_y]),           \"x\", markersize=12, label=\"Ours\")\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project448",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
